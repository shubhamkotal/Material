
Sure! Here are the 3 concise paragraphs with short titles for each:


---

1. Missing benchmark results
The model documentation does not include benchmark results comparing the performance of LightGBM with other models like Random Forest or XGBoost. This limits transparency around model selection and makes it unclear whether the chosen model was objectively the best performer.

2. Unreported event rate
The percentage of fraud events in the training sample is not mentioned. This is critical to assess class imbalance. Without this, there is a risk that the model may have learned predominantly from non-fraud transactions, affecting its sensitivity to actual fraud.

3. Retraining version clarity
The documentation states that the model will be retrained monthly but does not specify which version will be active during future quarters (e.g., Q2 2025) or the cutoff date for training data. This lack of clarity may lead to confusion in monitoring, reporting, and version control.

